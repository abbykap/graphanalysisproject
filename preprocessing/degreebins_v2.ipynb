{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing webbase-2001.mtx in domain Web...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "def count_degree_bins(file_path):\n",
    "    \"\"\"\n",
    "    Process a single Matrix Market edge list file and return degree counts for specified bins.\n",
    "    \"\"\"\n",
    "    degree_dict = defaultdict(int)\n",
    "    matrix_size_skipped = False  # Flag to skip the matrix size line\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            line = line.strip()\n",
    "            # Skip comment lines and metadata (starting with '%')\n",
    "            if line.startswith('%'):\n",
    "                continue\n",
    "\n",
    "            # Skip the matrix size line (first non-comment line)\n",
    "            if not matrix_size_skipped:\n",
    "                matrix_size_skipped = True\n",
    "                continue  # Skip the size line and move to the next line\n",
    "\n",
    "            parts = line.split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Process the actual data lines (node1, node2)\n",
    "                u = int(parts[0])\n",
    "                v = int(parts[1])\n",
    "\n",
    "                # Update the degrees for both nodes\n",
    "                degree_dict[u] += 1\n",
    "                degree_dict[v] += 1\n",
    "            except ValueError as e:\n",
    "                print(f\"Error parsing line {line_number} in {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not degree_dict:\n",
    "        print(f\"No valid edge data found in {file_path}.\")\n",
    "        return None\n",
    "\n",
    "    # Initialize bins\n",
    "    degree_bins = {\n",
    "        '0': 0,\n",
    "        '1': 0,\n",
    "        '2-10': 0,\n",
    "        '11-100': 0,\n",
    "        '101-1000': 0,\n",
    "        '1001-10000': 0,\n",
    "        '10001+': 0\n",
    "    }\n",
    "\n",
    "    # Classify degree counts into bins\n",
    "    for degree in degree_dict.values():\n",
    "        if degree == 0:\n",
    "            degree_bins['0'] += 1\n",
    "        elif degree == 1:\n",
    "            degree_bins['1'] += 1\n",
    "        elif 2 <= degree <= 10:\n",
    "            degree_bins['2-10'] += 1\n",
    "        elif 11 <= degree <= 100:\n",
    "            degree_bins['11-100'] += 1\n",
    "        elif 101 <= degree <= 1000:\n",
    "            degree_bins['101-1000'] += 1\n",
    "        elif 1001 <= degree <= 10000:\n",
    "            degree_bins['1001-10000'] += 1\n",
    "        else:\n",
    "            degree_bins['10001+'] += 1\n",
    "\n",
    "    return degree_bins\n",
    "\n",
    "def process_main_directory(main_directory, output_csv):\n",
    "    \"\"\"\n",
    "    Process each subdirectory within the main directory and save the results to a single CSV.\n",
    "    Each subdirectory represents a domain.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Loop through each subdirectory (domain)\n",
    "    for domain_name in os.listdir(main_directory):\n",
    "        domain_path = os.path.join(main_directory, domain_name)\n",
    "        if not os.path.isdir(domain_path):\n",
    "            continue  # Skip non-directory files\n",
    "\n",
    "        # Process each file in the subdirectory\n",
    "        for filename in os.listdir(domain_path):\n",
    "            if filename.endswith(\".mtx\"):\n",
    "                file_path = os.path.join(domain_path, filename)\n",
    "                print(f\"Processing {filename} in domain {domain_name}...\")\n",
    "\n",
    "                degree_bins = count_degree_bins(file_path)\n",
    "                if degree_bins:\n",
    "                    results.append({\n",
    "                        'filename': filename,\n",
    "                        'domain': domain_name,\n",
    "                        **degree_bins\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Skipping file {filename} due to lack of valid data.\")\n",
    "\n",
    "    # Write results to CSV\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['filename', 'domain', '0', '1', '2-10', '11-100', '101-1000', '1001-10000', '10001+']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Degree bin statistics for all domains saved to {output_csv}\")\n",
    "\n",
    "# Specify the main directory containing domain subdirectories\n",
    "main_directory = '/lustre/orion/gen150/world-shared/abby-summer24/nawsdatasets/degrees'  # Replace with the path to your main directory\n",
    "output_csv = 'all_degree_bin_statistics.csv'\n",
    "process_main_directory(main_directory, output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
