{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing euk...\n",
      "Error: File not found for euk: [Errno 2] No such file or directory: '/lustre/orion/gen150/world-shared/abby-summer24/hipmcldatasets/mtxfiles/eukus.mtx'\n",
      "Processing vir...\n",
      "Warning: Missing nodes: [0, 1, 2, 1783, 15899, 64272, 68694, 70479, 77166, 81956, 95204, 99196, 106475, 109170, 121849, 122399, 124406, 130739, 154059, 184396, 187370, 188858, 194482, 198182, 199010, 200960, 204609, 208626, 209789, 213989]\n",
      "Modularity for vir: -5.629331461536659e-06\n",
      "Processing arch...\n",
      "Error: File not found for arch: [Errno 2] No such file or directory: '/lustre/orion/gen150/world-shared/abby-summer24/hipmcldatasets/mtxfiles/archus.mtx'\n",
      "Results saved to modularity_results_hipdplprotein.csv\n"
     ]
    }
   ],
   "source": [
    "# import igraph as ig\n",
    "\n",
    "# def read_graph_from_edgelist_igraph(file_path):\n",
    "#     \"\"\"\n",
    "#     Reads an edge list from a Matrix Market format and returns an igraph Graph.\n",
    "#     \"\"\"\n",
    "#     edges = []\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             if line.startswith('%'):  # Skip comments\n",
    "#                 continue\n",
    "#             parts = line.split()\n",
    "#             if len(parts) >= 2:\n",
    "#                 u, v = int(parts[0]), int(parts[1])\n",
    "#                 edges.append((u, v))\n",
    "    \n",
    "#     G = ig.Graph(edges=edges)\n",
    "#     return G\n",
    "\n",
    "# def read_communities_igraph(file_path, graph):\n",
    "#     \"\"\"\n",
    "#     Reads the community file, skipping the empty '0' community, and returns a valid partition.\n",
    "#     Adjusts for one-based community IDs and ensures all nodes are covered.\n",
    "#     \"\"\"\n",
    "#     communities = []\n",
    "#     assigned_nodes = set()\n",
    "#     node_to_community = {}  # Track which community each node is in to detect duplicates\n",
    "\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             nodes = list(map(int, line.split()))\n",
    "#             if nodes:  # Ensure there are nodes\n",
    "#                 community_nodes = nodes[1:]  # Skip the community ID (first element)\n",
    "#                 if community_nodes:\n",
    "#                     communities.append(community_nodes)  # Append only if the community is not empty\n",
    "#                     for node in community_nodes:\n",
    "#                         if node in node_to_community:\n",
    "#                             print(f\"Warning: Node {node} appears in multiple communities!\")\n",
    "#                         node_to_community[node] = nodes[0]  # Track community ID for each node\n",
    "#                     assigned_nodes.update(community_nodes)\n",
    "    \n",
    "#     # Handle any missing nodes (nodes not assigned to any community)\n",
    "#     all_nodes = set(range(graph.vcount()))\n",
    "#     missing_nodes = all_nodes - assigned_nodes\n",
    "    \n",
    "#     # Print missing nodes\n",
    "#     if missing_nodes:\n",
    "#         print(f\"Warning: The following nodes are missing from the community file: {sorted(missing_nodes)}\")\n",
    "    \n",
    "#     # Low degree check for missing nodes\n",
    "#     low_degree_nodes = [node for node in missing_nodes if graph.degree(node) <= 1]\n",
    "#     if low_degree_nodes:\n",
    "#         print(f\"Low degree nodes (degree <= 1): {low_degree_nodes}\")\n",
    "\n",
    "#     # Uncomment the next lines if you want to assign missing nodes to singleton communities\n",
    "#     # for node in missing_nodes:\n",
    "#     #     communities.append([node])  # Each missing node gets its own community\n",
    "\n",
    "#     return communities\n",
    "\n",
    "# def calculate_modularity_igraph(graph, communities):\n",
    "#     \"\"\"\n",
    "#     Calculate the modularity of the given community structure on the graph using igraph.\n",
    "#     \"\"\"\n",
    "#     membership = [0] * graph.vcount()\n",
    "#     for i, community in enumerate(communities):\n",
    "#         for node in community:\n",
    "#             membership[node] = i  # Assign each node its community ID\n",
    "\n",
    "#     return graph.modularity(membership)\n",
    "\n",
    "# # File paths\n",
    "# edge_list_file = '/lustre/orion/gen150/world-shared/abby-summer24/nawsdatasets/alldegrees/road_central.mtx'\n",
    "# community_file = '/lustre/orion/gen150/world-shared/abby-summer24/nawsdatasets/outputs/road_central_with_weights.mtx.hipmcl64'\n",
    "\n",
    "# # Read the graph and communities\n",
    "# G = read_graph_from_edgelist_igraph(edge_list_file)\n",
    "# communities = read_communities_igraph(community_file, G)\n",
    "\n",
    "# # Calculate modularity\n",
    "# modularity_score = calculate_modularity_igraph(G, communities)\n",
    "# print(f\"Modularity of the given community structure: {modularity_score}\")\n",
    "import igraph as ig\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def read_graph_from_edgelist_igraph(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('%'):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                u, v = int(parts[0]), int(parts[1])\n",
    "                edges.append((u, v))\n",
    "    G = ig.Graph(edges=edges)\n",
    "    return G\n",
    "\n",
    "def read_communities_igraph(file_path, graph):\n",
    "    communities = []\n",
    "    assigned_nodes = set()\n",
    "    node_to_community = {}\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            nodes = list(map(int, line.split()))\n",
    "            if nodes:\n",
    "                community_nodes = nodes[1:]\n",
    "                communities.append(community_nodes)\n",
    "                for node in community_nodes:\n",
    "                    if node in node_to_community:\n",
    "                        print(f\"Warning: Node {node} appears in multiple communities!\")\n",
    "                    node_to_community[node] = nodes[0]\n",
    "                assigned_nodes.update(community_nodes)\n",
    "    \n",
    "    all_nodes = set(range(graph.vcount()))\n",
    "    missing_nodes = all_nodes - assigned_nodes\n",
    "    if missing_nodes:\n",
    "        print(f\"Warning: Missing nodes: {sorted(missing_nodes)}\")\n",
    "    \n",
    "    low_degree_nodes = [node for node in missing_nodes if graph.degree(node) <= 1]\n",
    "    if low_degree_nodes:\n",
    "        print(f\"Low degree nodes: {low_degree_nodes}\")\n",
    "\n",
    "    return communities\n",
    "\n",
    "def calculate_modularity_igraph(graph, communities):\n",
    "    membership = [0] * graph.vcount()\n",
    "    for i, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            membership[node] = i\n",
    "    return graph.modularity(membership)\n",
    "\n",
    "# Define file prefixes\n",
    "prefixes = [\n",
    "    'euk', 'virus', 'arch'\n",
    "# prefixes = [\n",
    "#     'europe_osm', 'road_usa', 'road_central', 'rgg_n_2_24_s0', \n",
    "#     'kron_g500-logn19', 'rgg_n_2_18_s0', 'delaunay_n24', \n",
    "#     'delaunay_n23', 'delaunay_n22'\n",
    "]\n",
    "# Directories for graphs and community files\n",
    "graph_dir = '/lustre/orion/gen150/world-shared/abby-summer24/hipmcldatasets/mtxfiles/'\n",
    "community_dir = '/lustre/orion/gen150/world-shared/abby-summer24/hipmcldatasets/proteinhipdplcommunities/new/'\n",
    "\n",
    "# Output CSV file\n",
    "output_csv = 'modularity_results_hipdplprotein.csv'\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open(output_csv, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Prefix', 'Modularity'])  # Write header\n",
    "\n",
    "    # Process each file prefix and write results to CSV\n",
    "    for prefix in prefixes:\n",
    "        edge_list_file = os.path.join(graph_dir, f'{prefix}.mtx')\n",
    "        community_file = os.path.join(community_dir, f'{prefix}.bin_new.txt')\n",
    "\n",
    "        print(f\"Processing {prefix}...\")\n",
    "        \n",
    "        try:\n",
    "            G = read_graph_from_edgelist_igraph(edge_list_file)\n",
    "            communities = read_communities_igraph(community_file, G)\n",
    "\n",
    "            modularity_score = calculate_modularity_igraph(G, communities)\n",
    "            print(f\"Modularity for {prefix}: {modularity_score}\")\n",
    "            \n",
    "            # Write result to CSV\n",
    "            writer.writerow([prefix, modularity_score])\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: File not found for {prefix}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {prefix}: {e}\")\n",
    "\n",
    "print(f\"Results saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
