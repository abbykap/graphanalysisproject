{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing arch...\n",
      "Average conductance for arch.mtx: 0.9999858504794483\n",
      "Minimum conductance for arch.mtx: 0.9927536231884058\n",
      "Maximum conductance for arch.mtx: 1.0\n",
      "Processing complete for arch\n",
      "\n",
      "\n",
      "Processing euk...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import igraph as ig\n",
    "import csv\n",
    "\n",
    "def read_graph_from_mtx(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('%'):  \n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                u, v = int(parts[0]), int(parts[1])\n",
    "                edges.append((u, v))\n",
    "    G = ig.Graph(edges=edges, directed=False)\n",
    "    return G\n",
    "\n",
    "def calculate_conductance_igraph(graph, community):\n",
    "    community_set = set(community)\n",
    "    cut_size = 0\n",
    "    vol_S = 0  # Volume of the community\n",
    "    \n",
    "    for node in community_set:\n",
    "        neighbors = graph.neighbors(node)\n",
    "        degree = graph.degree(node)\n",
    "        vol_S += degree  # Add to the community volume\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in community_set:\n",
    "                cut_size += 1  # Edge is leaving the community\n",
    "    \n",
    "    vol_complement = sum(graph.degree()) - vol_S  # Volume of the complement\n",
    "\n",
    "    if vol_S == 0 or vol_complement == 0:\n",
    "        return 0\n",
    "\n",
    "    conductance_value = cut_size / min(vol_S, vol_complement)\n",
    "    return conductance_value\n",
    "\n",
    "def read_communities_igraph(file_path):\n",
    "    communities = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            nodes = list(map(int, line.split()))\n",
    "            communities.append(nodes[1:])  # Skip the community ID, only add nodes\n",
    "    return communities\n",
    "\n",
    "# List of prefixes for the datasets\n",
    "prefixes = [\n",
    "    'arch', 'euk', 'virus'\n",
    "]\n",
    "\n",
    "# Directories for the files\n",
    "degree_dir = '/lustre/orion/gen150/world-shared/abby-summer24/hipmcldatasets/mtxfiles/'\n",
    "community_dir = '/lustre/orion/gen150/world-shared/abby-summer24/hipmcldatasets/proteinhipdplcommunities/new/'\n",
    "csv_file = 'conductance_hipdpl_proteins.csv'  # Define a combined CSV file name\n",
    "\n",
    "# Loop over each prefix\n",
    "for prefix in prefixes:\n",
    "    try:\n",
    "        print(f\"Processing {prefix}...\")\n",
    "\n",
    "        # Construct file paths for the graph and community files\n",
    "        mtx_file = os.path.join(degree_dir, f'{prefix}.mtx')\n",
    "        community_file = os.path.join(community_dir, f'{prefix}.bin_new2.txt')\n",
    "\n",
    "        # Check if the files exist before proceeding\n",
    "        if not os.path.exists(mtx_file) or not os.path.exists(community_file):\n",
    "            print(f\"Files for {prefix} not found, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Read the graph from the .mtx file\n",
    "        G = read_graph_from_mtx(mtx_file)\n",
    "\n",
    "        # Read the community structure from the file\n",
    "        communities = read_communities_igraph(community_file)\n",
    "\n",
    "        # Initialize variables to store min, max, and total conductance\n",
    "        total_conductance = 0\n",
    "        min_conductance = float('inf')\n",
    "        max_conductance = float('-inf')\n",
    "        results = []  # Accumulate results in memory\n",
    "\n",
    "        # Calculate conductance for each community and update min, max, and total\n",
    "        dataset_name = mtx_file.split('/')[-1]  # Get the dataset file name\n",
    "        for i, community in enumerate(communities):\n",
    "            conductance_value = calculate_conductance_igraph(G, community)\n",
    "            total_conductance += conductance_value\n",
    "\n",
    "            if conductance_value < min_conductance:\n",
    "                min_conductance = conductance_value\n",
    "\n",
    "            if conductance_value > max_conductance:\n",
    "                max_conductance = conductance_value\n",
    "\n",
    "            # Accumulate each community's conductance result\n",
    "            results.append([dataset_name, f'Community {i+1}', conductance_value])\n",
    "\n",
    "        # Get the average conductance\n",
    "        average_conductance = total_conductance / len(communities)\n",
    "\n",
    "        # Add summary stats to the results\n",
    "        results.append([dataset_name, 'Average conductance', average_conductance])\n",
    "        results.append([dataset_name, 'Minimum conductance', min_conductance])\n",
    "        results.append([dataset_name, 'Maximum conductance', max_conductance])\n",
    "\n",
    "        # Write everything to the CSV file in one go\n",
    "        with open(csv_file, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            \n",
    "            # Write a header only once, if this is the first time running the script (add checks if needed)\n",
    "            if csvfile.tell() == 0:\n",
    "                writer.writerow(['Dataset', 'Community', 'Conductance'])\n",
    "            \n",
    "            # Write all accumulated results\n",
    "            writer.writerows(results)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Average conductance for {dataset_name}: {average_conductance}\")\n",
    "        print(f\"Minimum conductance for {dataset_name}: {min_conductance}\")\n",
    "        print(f\"Maximum conductance for {dataset_name}: {max_conductance}\")\n",
    "        print(\"Processing complete for\", prefix)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {prefix}: {e}\")\n",
    "        continue  # Skip to the next dataset if an error occurs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
